{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "route = '87'\n",
    "period = 'daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time, sys\n",
    "from operator import itemgetter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import app libraries\n",
    "import reportcard.lib.StopsDB as StopsDB\n",
    "import reportcard.lib.BusAPI as BusAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database initialization\n",
    "db = StopsDB.MySQL('buses', 'buswatcher', 'njtransit', '127.0.0.1', route)\n",
    "conn = db.conn\n",
    "table_name = 'stop_approaches_log_' + route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if period == \"daily\":\n",
    "        final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND DATE(`timestamp`)=CURDATE() ) ORDER BY timestamp DESC;' % (self.table_name, self.stop))\n",
    "    elif self.period == \"yesterday\":\n",
    "        final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND (timestamp >= CURDATE() - INTERVAL 1 DAY AND timestamp < CURDATE())) ORDER BY timestamp DESC;' % (self.table_name, self.stop))\n",
    "    elif self.period==\"weekly\":\n",
    "        final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND (YEARWEEK(`timestamp`, 1) = YEARWEEK(CURDATE(), 1))) ORDER BY timestamp DESC;' % (self.table_name,self.stop))\n",
    "    elif self.period==\"history\":\n",
    "        final_approach_query = ('SELECT * FROM %s WHERE stop_id= %s ORDER BY timestamp DESC;' % (self.table_name,self.stop))\n",
    "    else:\n",
    "        raise RuntimeError('Bad request sucker!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Break the next block up and examine the products step by step for errors/duplicates/missing rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_approach_query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8188e0ebb7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get data and basic cleanup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_approach_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# arrivals table and deltas are all re-generated on the fly for every view now -- easier, but might lead to inconsistent/innaccurate results over time?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cars'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'consist'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rn'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'scheduled'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimestamp_fix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'final_approach_query' is not defined"
     ]
    }
   ],
   "source": [
    "# get data and basic cleanup\n",
    "df_temp = pd.read_sql_query(final_approach_query, self.conn) # arrivals table and deltas are all re-generated on the fly for every view now -- easier, but might lead to inconsistent/innaccurate results over time?\n",
    "df_temp = df_temp.drop(columns=['cars', 'consist', 'fd', 'm', 'name', 'rn', 'scheduled'])\n",
    "df_temp = timestamp_fix(df_temp)\n",
    "\n",
    "# split final approach history (sorted by timestamp) at each change in vehicle_id outputs a list of dfs -- per https://stackoverflow.com/questions/41144231/python-how-to-split-pandas-dataframe-into-subsets-based-on-the-value-in-the-fir\n",
    "final_approach_dfs = [g for i, g in df_temp.groupby(df_temp['v'].ne(df_temp['v'].shift()).cumsum())]\n",
    "\n",
    "try:\n",
    "    # take the last V(ehicle) approach in each df and add it to final list of arrivals\n",
    "    arrivals_list_final_df = pd.DataFrame()\n",
    "    for final_approach in final_approach_dfs:  # iterate over every final approach\n",
    "        arrival_insert_df = final_approach.tail(1)  # take the last observation\n",
    "        arrivals_list_final_df = arrivals_list_final_df.append(arrival_insert_df)  # insert into df\n",
    "\n",
    "    # calc interval between last bus for each row, fill NaNs\n",
    "    arrivals_list_final_df['delta']=(arrivals_list_final_df['timestamp'] - arrivals_list_final_df['timestamp'].shift(-1)).fillna(0)\n",
    "\n",
    "    # housekeeping ---------------------------------------------------\n",
    "\n",
    "    # set stop_name\n",
    "    stop_name = arrivals_list_final_df['stop_name'].iloc[0]\n",
    "    return arrivals_list_final_df, stop_name\n",
    "\n",
    "except:\n",
    "    arrivals_list_final_df=\\\n",
    "        pd.DataFrame(\\\n",
    "            columns=['pkey','pt','rd','stop_id','stop_name','v','timestamp','delta'],\\\n",
    "            data=[['0000000', '3', self.route, self.stop,'N/A', 'N/A', datetime.time(0,1), datetime.timedelta(seconds=0)]])\n",
    "    stop_name = 'N/A'\n",
    "    self.arrivals_table_time_created = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Original Code - ReportCard.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time, sys\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "\n",
    "# database config\n",
    "import os\n",
    "try:\n",
    "    db_state = os.environ['REPORTCARD_PRODUCTION']\n",
    "    db_server = '192.168.1.181'\n",
    "except:\n",
    "    db_server = '127.0.0.1'\n",
    "\n",
    "\n",
    "# import app libraries\n",
    "import StopsDB, BusAPI\n",
    "\n",
    "# setup cache\n",
    "from easy_cache import ecached\n",
    "from django.conf import settings\n",
    "settings.configure(DEBUG=True, DJANGO_SETTINGS_MODULE=\"mysite_django.settings\")\n",
    "\n",
    "def get_cache_timeout(self,route,stop,period):\n",
    "    if period == \"hourly\":\n",
    "        cache_timeout = 60 # 1 min\n",
    "    elif period == \"daily\":\n",
    "        cache_timeout = 3600  # 1 hour\n",
    "    elif period == \"yesterday\":\n",
    "        cache_timeout = 86400  # 1 day\n",
    "    elif period == \"weekly\":\n",
    "        cache_timeout = 86400  # 1 day\n",
    "    elif period == \"history\":\n",
    "        cache_timeout = 604800  # 1 week\n",
    "    else:\n",
    "        raise RuntimeError('Bad request sucker!')\n",
    "    return cache_timeout\n",
    "\n",
    "# def invalidate_cache(n):\n",
    "#     time_consuming_operation.invalidate_cache_by_key(n)\n",
    "\n",
    "# common functions\n",
    "def timestamp_fix(data): # trim the microseconds off the timestamp and convert it to datetime format\n",
    "    data['timestamp'] = data['timestamp'].str.split('.').str.get(0)\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'],errors='coerce')\n",
    "    data = data.set_index(pd.DatetimeIndex(data['timestamp']))\n",
    "    # data = data.set_index(pd.DatetimeIndex(data['timestamp'], drop=False)\n",
    "    return data\n",
    "\n",
    "# primary classes\n",
    "class RouteReport:\n",
    "\n",
    "    class Path():\n",
    "        def __init__(self):\n",
    "            self.name = 'Path'\n",
    "            self.stops = []\n",
    "            self.id = ''\n",
    "            self.d = ''\n",
    "            self.dd = ''\n",
    "\n",
    "    def __init__(self, source, route, reportcard_routes, grade_descriptions):\n",
    "\n",
    "        # apply passed parameters to instance\n",
    "        self.source = source\n",
    "        self.route = route\n",
    "        self.reportcard_routes = reportcard_routes\n",
    "        self.grade_descriptions = grade_descriptions\n",
    "\n",
    "        # database initialization\n",
    "        self.db = StopsDB.MySQL('buses', 'buswatcher', 'njtransit', db_server, self.route)\n",
    "        self.conn = self.db.conn\n",
    "        self.table_name = 'stop_approaches_log_' + self.route\n",
    "\n",
    "        # populate report card data\n",
    "        self.routename = self.get_routename(self.route)\n",
    "        self.get_servicelist()\n",
    "        self.compute_grade()\n",
    "        self.route_stop_list = self.get_stoplist(self.route)\n",
    "        self.bunching_leaderboard = self.get_bunching_leaderboard('daily',self.route)\n",
    "\n",
    "    @ecached('get_routename:{route}',86400) # cache per route, 24 hour expire\n",
    "    def get_routename(self,route):\n",
    "        routedata = BusAPI.parse_xml_getRoutePoints(BusAPI.get_xml_data(self.source, 'routes', route=route))\n",
    "        return routedata[0].nm\n",
    "\n",
    "    def get_servicelist(self):\n",
    "        for route in self.reportcard_routes:\n",
    "            if route['route'] == self.route:\n",
    "                self.servicelist = []\n",
    "                for service in route['services']:\n",
    "                    insertion = {'destination':service[0],'service_id':service[1]}\n",
    "                    self.servicelist.append(insertion)\n",
    "                # populate servicelist with stoplist?\n",
    "                # for service in self.servicelist:\n",
    "                #   how to do it?\n",
    "        return\n",
    "\n",
    "\n",
    "    def compute_grade(self):\n",
    "        # for now, grade is coded manually in route_config.py\n",
    "        # FUTURE fancier grade calculation based on historical data\n",
    "        for route in self.reportcard_routes:\n",
    "            if route['route'] == self.route:\n",
    "                self.grade = route['grade']\n",
    "                self.description_long = route['description_long']\n",
    "                self.schedule_url = route['schedule_url']\n",
    "                self.moovit_url = route['moovit_url']\n",
    "                for entry in self.grade_descriptions:\n",
    "                    if self.grade == entry['grade']:\n",
    "                        self.grade_description = entry['description']\n",
    "                    else:\n",
    "                        pass\n",
    "                if not self.grade_description:\n",
    "                    grade_description = 'Cannot find a description for that grade.'\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        return\n",
    "\n",
    "\n",
    "    # ecached gives a pickling error on Route.Path here\n",
    "    def get_stoplist(self, route):\n",
    "        routedata = BusAPI.parse_xml_getRoutePoints(BusAPI.get_xml_data(self.source, 'routes', route=self.route))\n",
    "        route_stop_list = []\n",
    "        for r in routedata:\n",
    "            path_list = []\n",
    "            for path in r.paths:\n",
    "                stops_points = RouteReport.Path()\n",
    "                for point in path.points:\n",
    "                    if isinstance(point, BusAPI.Route.Stop):\n",
    "                        stops_points.stops.append(point)\n",
    "                stops_points.id=path.id\n",
    "                stops_points.d=path.d\n",
    "                stops_points.dd=path.dd\n",
    "                path_list.append(stops_points) # path_list is now a couple of Path instances, plus the metadata id,d,dd fields\n",
    "            route_stop_list.append(path_list)\n",
    "        return route_stop_list[0] # transpose a single copy since the others are all repeats (can be verified by path ids)\n",
    "\n",
    "\n",
    "    @ecached('get_bunching_leaderboard:{route}:{period}',3600) # cache per route, period, 1 hour expire\n",
    "    def get_bunching_leaderboard(self, period, route):\n",
    "        # generates top 10 list of stops on the route by # of bunching incidents for yesterday\n",
    "        # as well as the hourly frequency table\n",
    "\n",
    "        # sample query\n",
    "        # SELECT * FROM stop_approaches_log_87 WHERE (stop_id= 20935 AND DATE(timestamp)=CURDATE()) ORDER BY timestamp DESC;\n",
    "\n",
    "        bunching_leaderboard = []\n",
    "\n",
    "        # loop over each service and stop\n",
    "        for service in self.route_stop_list:\n",
    "            # print service.id\n",
    "            for stop in service.stops:\n",
    "                bunch_total = 0\n",
    "                report = StopReport(self.route, stop.identity,period)\n",
    "                # calculate number of bunches\n",
    "                for (index, row) in report.arrivals_list_final_df.iterrows():\n",
    "                    if (row.delta > report.bigbang) and (row.delta <= report.bunching_interval):\n",
    "                        # print \"\\t\",row.v,\"\\t\",stop.st,\"\\t\\t\\t\\t\\t\",row.timestamp,\"\\t\",row.delta\n",
    "                        bunch_total += 1\n",
    "                        # sys.stdout.write('.'),\n",
    "\n",
    "                # append dict to the list\n",
    "                bunching_leaderboard.append((stop.st, bunch_total,stop.identity))\n",
    "\n",
    "                # now work on the hourly frequency report\n",
    "\n",
    "        # sort stops by number of bunchings, grab first 10\n",
    "        bunching_leaderboard.sort(key=itemgetter(1), reverse=True)\n",
    "        bunching_leaderboard = bunching_leaderboard[:10]\n",
    "\n",
    "        return bunching_leaderboard\n",
    "\n",
    "\n",
    "class StopReport:\n",
    "\n",
    "    def __init__(self,route,stop,period):\n",
    "\n",
    "        # apply passed parameters to instance\n",
    "        self.route=route\n",
    "        self.stop=stop\n",
    "        self.period=period\n",
    "\n",
    "        # database initialization\n",
    "        self.db = StopsDB.MySQL('buses', 'buswatcher', 'njtransit', db_server,  self.route)\n",
    "        self.conn = self.db.conn\n",
    "        self.table_name = 'stop_approaches_log_' + self.route\n",
    "\n",
    "        # populate stop report data\n",
    "        self.arrivals_list_final_df, self.stop_name = self.get_arrivals(self.route,self.stop,self.period)\n",
    "        # self.hourly_frequency = self.get_hourly_frequency(self.route,self.stop,self.period) # this dies if there are no arrivals in the period\n",
    "\n",
    "        # constants\n",
    "        self.bunching_interval = datetime.timedelta(minutes=3)\n",
    "        self.bigbang = datetime.timedelta(seconds=0)\n",
    "\n",
    "\n",
    "    @ecached('get_arrivals:{route}:{stop}:{period}', timeout=get_cache_timeout) # dynamic timeout\n",
    "    def get_arrivals(self,route,stop,period):\n",
    "\n",
    "        if self.period == \"daily\":\n",
    "            final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND DATE(`timestamp`)=CURDATE() ) ORDER BY timestamp DESC;' % (self.table_name, self.stop))\n",
    "        elif self.period == \"yesterday\":\n",
    "            final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND (timestamp >= CURDATE() - INTERVAL 1 DAY AND timestamp < CURDATE())) ORDER BY timestamp DESC;' % (self.table_name, self.stop))\n",
    "        elif self.period==\"weekly\":\n",
    "            final_approach_query = ('SELECT * FROM %s WHERE (stop_id= %s AND (YEARWEEK(`timestamp`, 1) = YEARWEEK(CURDATE(), 1))) ORDER BY timestamp DESC;' % (self.table_name,self.stop))\n",
    "        elif self.period==\"history\":\n",
    "            final_approach_query = ('SELECT * FROM %s WHERE stop_id= %s ORDER BY timestamp DESC;' % (self.table_name,self.stop))\n",
    "        else:\n",
    "            raise RuntimeError('Bad request sucker!')\n",
    "\n",
    "        # get data and basic cleanup\n",
    "        df_temp = pd.read_sql_query(final_approach_query, self.conn) # arrivals table and deltas are all re-generated on the fly for every view now -- easier, but might lead to inconsistent/innaccurate results over time?\n",
    "        df_temp = df_temp.drop(columns=['cars', 'consist', 'fd', 'm', 'name', 'rn', 'scheduled'])\n",
    "        df_temp = timestamp_fix(df_temp)\n",
    "\n",
    "        # split final approach history (sorted by timestamp) at each change in vehicle_id outputs a list of dfs -- per https://stackoverflow.com/questions/41144231/python-how-to-split-pandas-dataframe-into-subsets-based-on-the-value-in-the-fir\n",
    "        final_approach_dfs = [g for i, g in df_temp.groupby(df_temp['v'].ne(df_temp['v'].shift()).cumsum())]\n",
    "\n",
    "        try:\n",
    "            # take the last V(ehicle) approach in each df and add it to final list of arrivals\n",
    "            arrivals_list_final_df = pd.DataFrame()\n",
    "            for final_approach in final_approach_dfs:  # iterate over every final approach\n",
    "                arrival_insert_df = final_approach.tail(1)  # take the last observation\n",
    "                arrivals_list_final_df = arrivals_list_final_df.append(arrival_insert_df)  # insert into df\n",
    "\n",
    "            # calc interval between last bus for each row, fill NaNs\n",
    "            arrivals_list_final_df['delta']=(arrivals_list_final_df['timestamp'] - arrivals_list_final_df['timestamp'].shift(-1)).fillna(0)\n",
    "\n",
    "            # housekeeping ---------------------------------------------------\n",
    "\n",
    "            # set stop_name\n",
    "            stop_name = arrivals_list_final_df['stop_name'].iloc[0]\n",
    "            return arrivals_list_final_df, stop_name\n",
    "\n",
    "        except:\n",
    "            arrivals_list_final_df=\\\n",
    "                pd.DataFrame(\\\n",
    "                    columns=['pkey','pt','rd','stop_id','stop_name','v','timestamp','delta'],\\\n",
    "                    data=[['0000000', '3', self.route, self.stop,'N/A', 'N/A', datetime.time(0,1), datetime.timedelta(seconds=0)]])\n",
    "            stop_name = 'N/A'\n",
    "            self.arrivals_table_time_created = datetime.datetime.now()\n",
    "            return arrivals_list_final_df, stop_name\n",
    "\n",
    "\n",
    "    # @ecached('get_hourly_frequency:{route}:{stop}:{period}', timeout=get_cache_timeout)\n",
    "    def get_hourly_frequency(self,route,stop,period):\n",
    "\n",
    "        self.arrivals_list_final_df['delta_int']=self.arrivals_list_final_df['delta'].dt.seconds\n",
    "        hourly_frequency = self.arrivals_list_final_df.resample('1H').mean('delta_int') # this works but it creates a groupby object, and doesn't actually compute the mean.\n",
    "\n",
    "        return hourly_frequency\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
