{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. run_id assignor\n",
    "\n",
    "# trains model using a few weeks of statewide bus locations for all NJTransit buses from June 2018\n",
    "# given a vehicle id (obtained from Clever Devices API getStopPredictions.jsp)\n",
    "# will predict what GTFS run # the bus is on\n",
    "# allowing for the vehicle's schedule to be cross-referenced\n",
    "# n.b. the run_id is omitted from the getStopPredictions.jsp API response for inbound buses to the stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'nj'\n",
    "route = 119"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relative import\n",
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) \n",
    "\n",
    "from src.buses.reportcard_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training dataset - takes about a minute for Rt. 119\n",
    "# how long for entire database?\n",
    "\n",
    "from mysql.connector import connection\n",
    "db_user ='buswatcher'\n",
    "db_password = 'njtransit'\n",
    "db_host = 'localhost'\n",
    "db_name = 'bus_position_log'\n",
    "conn = connection.MySQLConnection(user=db_user, password=db_password, host=db_host, database=db_name)\n",
    "\n",
    "arrival_query = ('SELECT * FROM run_predictor_training_set WHERE (rt=\"%s\");' % route)\n",
    "df = pd.read_sql_query(arrival_query, conn)\n",
    "\n",
    "df.replace(\n",
    "        to_replace='MAN',\n",
    "        value=unicode('666'), # vs value=np.NaN,\n",
    "        inplace=True,\n",
    "        limit=None,\n",
    "        regex=False, \n",
    "        method='pad')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the timestamp\n",
    "df['timestamp'] = df['timestamp'].str.split('.').str.get(0)\n",
    "df = df.set_index(pd.DatetimeIndex(df['timestamp']), drop=False)\n",
    "\n",
    "# extract the time\n",
    "df['timestamp_ml'] = df.index.time\n",
    "df['timestamp_ml'] = df['timestamp_ml'].apply(lambda x: float(str(x).replace(\":\",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup columns\n",
    "\n",
    "# negatives in lon\n",
    "df['lon'] = abs(df['lon'])\n",
    "\n",
    "# straggler strings in run\n",
    "df['run'] = df['run'].str.replace(r'\\D+', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df['run'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup training and test set, LogRegression and RandomForest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512\n",
    "\n",
    "features = ['lat','lon','bid','rt','run','timestamp_ml']\n",
    "X_train = df.loc[:,features]\n",
    "X_test = df.loc[:,features]\n",
    "y_train = df.loc[:,['run']]\n",
    "y_test = df.loc[:,['run']]\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "l = LogisticRegression()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "r = RandomForestClassifier(n_estimators=25,max_depth=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature hashing --> LogRegression and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512\n",
    "\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "X_train_hash = copy.copy(X_train)\n",
    "X_test_hash = copy.copy(X_test)\n",
    "for i in range(X_train_hash.shape[1]):\n",
    "    X_train_hash.iloc[:,i]=X_train_hash.iloc[:,i].astype('str')\n",
    "for i in range(X_test_hash.shape[1]):\n",
    "    X_test_hash.iloc[:,i]=X_test_hash.iloc[:,i].astype('str')\n",
    "h = FeatureHasher(n_features=100,input_type=\"string\")\n",
    "X_train_hash = h.transform(X_train_hash.values)\n",
    "X_test_hash = h.transform(X_test_hash.values)\n",
    "\n",
    "#l.fit(X_train_hash,y_train)\n",
    "l.fit(X_train_hash,y_train.values.ravel())\n",
    "y_pred = l.predict_proba(X_test_hash)\n",
    "print(log_loss(y_test,y_pred))#0.4\n",
    "\n",
    "#r.fit(X_train_hash,y_train)\n",
    "r.fit(X_train_hash,y_train.values.ravel())\n",
    "y_pred = r.predict_proba(X_test_hash)\n",
    "print(log_loss(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'runid_predictor_model_hashing_logistic.sav'\n",
    "pickle.dump(l, open(filename, 'wb'))\n",
    "filename2 = 'runid_predictor_model_hashing_randomforest.sav'\n",
    "pickle.dump(r, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one-hot encoding --> LogRegression and RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://blog.myyellowroad.com/using-categorical-data-in-machine-learning-with-python-from-dummy-variables-to-deep-category-66041f734512\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_train_values = X_train.values\n",
    "X_test_values = X_test.values\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train_values)\n",
    "X_train_one_hot = enc.transform(X_train_values)\n",
    "X_test_one_hot = enc.transform(X_test_values)\n",
    "l.fit(X_train_one_hot,y_train)\n",
    "y_pred = l.predict_proba(X_test_one_hot)\n",
    "print(log_loss(y_test,y_pred))\n",
    "r.fit(X_train_one_hot,y_train)\n",
    "y_pred = r.predict_proba(X_test_one_hot)\n",
    "print(log_loss(y_test,y_pred))\n",
    "print(X_train_one_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with changes for preprocessing the category labels from \n",
    "# https://stackoverflow.com/questions/43588679/issue-with-onehotencoder-for-categorical-features\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# turns the labels into a numpy array\n",
    "cat_features = ['lat','lon','bid','rt','run','timestamp_ml']\n",
    "encoder = preprocessing.LabelBinarizer()\n",
    "new_cat_features = encoder.fit_transform(cat_features)\n",
    "\n",
    "# build and fit the model\n",
    "X_train_values = X_train.values\n",
    "X_test_values = X_test.values\n",
    "enc = OneHotEncoder(handle_unknown='ignore',categorical_features=new_cat_features)\n",
    "enc.fit(X_train_values)\n",
    "X_train_one_hot = enc.transform(X_train_values)\n",
    "X_test_one_hot = enc.transform(X_test_values)\n",
    "l.fit(X_train_one_hot,y_train)\n",
    "\n",
    "# score some predictions\n",
    "y_pred = l.predict_proba(X_test_one_hot)\n",
    "print(log_loss(y_test,y_pred))\n",
    "r.fit(X_train_one_hot,y_train)\n",
    "y_pred = r.predict_proba(X_test_one_hot)\n",
    "print(log_loss(y_test,y_pred))\n",
    "print(X_train_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.run.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# do a specific operational prediction - here is a getStopPrediction, what run is it on?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call stopwatcher --- use it by feeding it parameters from stopwatcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUTURE WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. look up the run and scheduled stop time \n",
    "# to see how late it is, and then log that to a run history file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.can we also back out from this to the entire route ?\n",
    "# (e.g. look up all stops for the run and then go find the vehicle in the busgrabber corpus if we've been grabbing that all along?)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:buswatcher]",
   "language": "python",
   "name": "conda-env-buswatcher-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
